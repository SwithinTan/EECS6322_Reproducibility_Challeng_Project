{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from networks.resnet import resnet50\n",
    "from networks.base_model import BaseModel, init_weights\n",
    "import os\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from data import create_dataloader\n",
    "from options.train_options import TrainOptions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmnetations = ['no_aug', 'gaussian', 'jpeg', 'blur_jpeg_5', 'blur_jpeg_1']\n",
    "models = ['resnet50']\n",
    "max_datasets = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.total_steps = 0\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "        self.device = torch.device('cuda:{}'.format(opt.gpu_ids[0])) if opt.gpu_ids else torch.device('cpu')\n",
    "\n",
    "    def save_networks(self, epoch):\n",
    "        save_filename = 'model_epoch_%s.pth' % epoch\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "\n",
    "        # serialize model and optimizer to dict\n",
    "        state_dict = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer' : self.optimizer.state_dict(),\n",
    "            'total_steps' : self.total_steps,\n",
    "        }\n",
    "\n",
    "        torch.save(state_dict, save_path)\n",
    "\n",
    "    # load models from the disk\n",
    "    def load_networks(self, epoch):\n",
    "        load_filename = 'model_epoch_%s.pth' % epoch\n",
    "        load_path = os.path.join(self.save_dir, load_filename)\n",
    "\n",
    "        print('loading the model from %s' % load_path)\n",
    "        # if you are using PyTorch newer than 0.4 (e.g., built from\n",
    "        # GitHub source), you can remove str() on self.device\n",
    "        state_dict = torch.load(load_path, map_location=self.device)\n",
    "        if hasattr(state_dict, '_metadata'):\n",
    "            del state_dict._metadata\n",
    "\n",
    "        self.model.load_state_dict(state_dict['model'])\n",
    "        self.total_steps = state_dict['total_steps']\n",
    "\n",
    "        if self.isTrain and not self.opt.new_optim:\n",
    "            self.optimizer.load_state_dict(state_dict['optimizer'])\n",
    "            ### move optimizer state to GPU\n",
    "            for state in self.optimizer.state.values():\n",
    "                for k, v in state.items():\n",
    "                    if torch.is_tensor(v):\n",
    "                        state[k] = v.to(self.device)\n",
    "\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = self.opt.lr\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n",
    "\n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            self.forward()\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n",
    "\n",
    "\n",
    "\n",
    "class Trainer(BaseModel):\n",
    "    def name(self):\n",
    "        return 'Trainer'\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        super(Trainer, self).__init__(opt)\n",
    "\n",
    "        if self.isTrain and not opt.continue_train:\n",
    "            self.model = resnet50(pretrained=True)\n",
    "            self.model.fc = nn.Linear(2048, 1)\n",
    "            torch.nn.init.normal_(self.model.fc.weight.data, 0.0, opt.init_gain)\n",
    "\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            self.model = resnet50(num_classes=1)\n",
    "\n",
    "        if self.isTrain:\n",
    "            self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "            # initialize optimizers\n",
    "            if opt.optim == 'adam':\n",
    "                self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            elif opt.optim == 'sgd':\n",
    "                self.optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                                lr=opt.lr, momentum=0.0, weight_decay=0)\n",
    "            else:\n",
    "                raise ValueError(\"optim should be [adam, sgd]\")\n",
    "\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            self.load_networks(opt.epoch)\n",
    "        self.model.to(opt.gpu_ids[0])\n",
    "\n",
    "\n",
    "    def adjust_learning_rate(self, min_lr=1e-6):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] /= 10.\n",
    "            if param_group['lr'] < min_lr:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input[0].to(self.device)\n",
    "        self.label = input[1].to(self.device).float()\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        self.output = self.model(self.input)\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self.loss_fn(self.output.squeeze(1), self.label)\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.forward()\n",
    "        self.loss = self.loss_fn(self.output.squeeze(1), self.label)\n",
    "        self.optimizer.zero_grad()\n",
    "        self.loss.backward()\n",
    "        self.optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Currently assumes jpg_prob, blur_prob 0 or 1\"\"\"\n",
    "def get_val_opt():\n",
    "    val_opt = TrainOptions().parse(print_options=False)\n",
    "    val_opt.dataroot = '{}/{}/'.format(val_opt.dataroot, val_opt.val_split)\n",
    "    val_opt.isTrain = False\n",
    "    val_opt.no_resize = False\n",
    "    val_opt.no_crop = False\n",
    "    val_opt.serial_batches = True\n",
    "    val_opt.jpg_method = ['pil']\n",
    "    if len(val_opt.blur_sig) == 2:\n",
    "        b_sig = val_opt.blur_sig\n",
    "        val_opt.blur_sig = [(b_sig[0] + b_sig[1]) / 2]\n",
    "    if len(val_opt.jpg_qual) != 1:\n",
    "        j_qual = val_opt.jpg_qual\n",
    "        val_opt.jpg_qual = [int((j_qual[0] + j_qual[-1]) / 2)]\n",
    "\n",
    "    return val_opt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    opt = TrainOptions().parse()\n",
    "    opt.dataroot = '{}/{}/'.format(opt.dataroot, opt.train_split)\n",
    "    val_opt = get_val_opt()\n",
    "\n",
    "    data_loader = create_dataloader(opt)\n",
    "    dataset_size = len(data_loader)\n",
    "    print('#training images = %d' % dataset_size)\n",
    "\n",
    "    train_writer = SummaryWriter(os.path.join(opt.checkpoints_dir, opt.name, \"train\"))\n",
    "    val_writer = SummaryWriter(os.path.join(opt.checkpoints_dir, opt.name, \"val\"))\n",
    "\n",
    "    model = Trainer(opt)\n",
    "    early_stopping = EarlyStopping(patience=opt.earlystop_epoch, delta=-0.001, verbose=True)\n",
    "    for epoch in range(opt.niter):\n",
    "        epoch_start_time = time.time()\n",
    "        iter_data_time = time.time()\n",
    "        epoch_iter = 0\n",
    "\n",
    "        for i, data in enumerate(data_loader):\n",
    "            model.total_steps += 1\n",
    "            epoch_iter += opt.batch_size\n",
    "\n",
    "            model.set_input(data)\n",
    "            model.optimize_parameters()\n",
    "\n",
    "            if model.total_steps % opt.loss_freq == 0:\n",
    "                print(\"Train loss: {} at step: {}\".format(model.loss, model.total_steps))\n",
    "                train_writer.add_scalar('loss', model.loss, model.total_steps)\n",
    "\n",
    "            if model.total_steps % opt.save_latest_freq == 0:\n",
    "                print('saving the latest model %s (epoch %d, model.total_steps %d)' %\n",
    "                    (opt.name, epoch, model.total_steps))\n",
    "                model.save_networks('latest')\n",
    "\n",
    "            # print(\"Iter time: %d sec\" % (time.time()-iter_data_time))\n",
    "            # iter_data_time = time.time()\n",
    "\n",
    "        if epoch % opt.save_epoch_freq == 0:\n",
    "            print('saving the model at the end of epoch %d, iters %d' %\n",
    "                (epoch, model.total_steps))\n",
    "            model.save_networks('latest')\n",
    "            model.save_networks(epoch)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        acc, ap = validate(model.model, val_opt)[:2]\n",
    "        val_writer.add_scalar('accuracy', acc, model.total_steps)\n",
    "        val_writer.add_scalar('ap', ap, model.total_steps)\n",
    "        print(\"(Val @ epoch {}) acc: {}; ap: {}\".format(epoch, acc, ap))\n",
    "\n",
    "        early_stopping(acc, model)\n",
    "        if early_stopping.early_stop:\n",
    "            cont_train = model.adjust_learning_rate()\n",
    "            if cont_train:\n",
    "                print(\"Learning rate dropped by 10, continue training...\")\n",
    "                early_stopping = EarlyStopping(patience=opt.earlystop_epoch, delta=-0.002, verbose=True)\n",
    "            else:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
