{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXfhPMLc5Ecc"
      },
      "source": [
        "# Download the saved models from pth files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82byzn5F4nbq",
        "outputId": "feac5fb5-40f0-4e2d-a45a-af55bc74a39e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wFB32vUF3ZuesxYZdfEyVtk-nvpYgKFO\n",
            "To: /content/models.zip\n",
            "100% 5.10G/5.10G [01:46<00:00, 48.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "!gdown 1wFB32vUF3ZuesxYZdfEyVtk-nvpYgKFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I80rdK6c5NZM",
        "outputId": "171e2aa5-94d2-4534-f8c5-b972a59f4c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  inflating: ./models/models/8_datasets/blur_jpeg_5/resnet18/checkpoint.pth  \n",
            "  inflating: ./models/models/8_datasets/blur_jpeg_5/vgg11/checkpoint.pth  \n",
            "  inflating: ./models/models/2_datasets/no_aug/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/2_datasets/blur_jpeg_5/resnet50/checkpoint.pth  \n",
            "   creating: ./models/models/new_dataset/progan2/None_datasets/gaussian/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/None_datasets/blur_jpeg_1/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/None_datasets/no_aug/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/None_datasets/jpeg/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/None_datasets/blur_jpeg_5/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/20_classes/gaussian/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/20_classes/blur_jpeg_1/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/20_classes/no_aug/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/20_classes/jpeg/resnet50/\n",
            "   creating: ./models/models/new_dataset/progan2/20_classes/blur_jpeg_5/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/None_datasets/gaussian/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/None_datasets/blur_jpeg_1/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/None_datasets/no_aug/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/None_datasets/jpeg/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/None_datasets/blur_jpeg_5/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/20_classes /gaussian/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/20_classes /blur_jpeg_1/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/20_classes /no_aug/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/20_classes /jpeg/resnet50/\n",
            "   creating: ./models/models/new_dataset/stylegan2/20_classes /blur_jpeg_5/resnet50/\n",
            "  inflating: ./models/models/new_dataset/progan2/None_datasets/gaussian/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/progan2/None_datasets/blur_jpeg_1/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/progan2/None_datasets/no_aug/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/progan2/None_datasets/jpeg/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/progan2/None_datasets/blur_jpeg_5/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/stylegan2/None_datasets/gaussian/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/stylegan2/None_datasets/blur_jpeg_1/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/stylegan2/None_datasets/no_aug/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/stylegan2/None_datasets/jpeg/resnet50/checkpoint.pth  \n",
            "  inflating: ./models/models/new_dataset/stylegan2/None_datasets/blur_jpeg_5/resnet50/checkpoint.pth  \n"
          ]
        }
      ],
      "source": [
        "!unzip ./models.zip -d ./models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqmNcFbFePJb",
        "outputId": "ddb1ea0c-7c18-470e-f881-6196a8a0720c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_dct\n",
            "  Downloading torch_dct-0.1.6-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from torch_dct) (2.0.0+cu118)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->torch_dct) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->torch_dct) (3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->torch_dct) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->torch_dct) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->torch_dct) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=0.4.1->torch_dct) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=0.4.1->torch_dct) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=0.4.1->torch_dct) (16.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=0.4.1->torch_dct) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=0.4.1->torch_dct) (1.3.0)\n",
            "Installing collected packages: torch_dct\n",
            "Successfully installed torch_dct-0.1.6\n"
          ]
        }
      ],
      "source": [
        "!cp -r ./ReproducabilityCNNEasyToSpot/gandetect ./\n",
        "import gandetect\n",
        "!pip install torch_dct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3QcczOU8YtB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gandetect\n",
        "# Load the saved model from file\n",
        "all_data_jpeg = torch.load('/content/models/models/20_datasets/jpeg/resnet50/checkpoint.pth')\n",
        "# all_data_no_aug = torch.load()\n",
        "# all_data_gaussian = torch.load()\n",
        "# all_data_blur_jpeg_1 = \n",
        "# all_data_blur_jpeg_5 = \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blIu4eKn92De"
      },
      "outputs": [],
      "source": [
        "all_data_jpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCVkPzLkgD-s"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import multiprocessing as mp\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.metrics import average_precision_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "from gandetect.dataloader import load_data\n",
        "from gandetect.transforms import TEST_TRANSFORM, TEST_TRANSFORM_DCT\n",
        "from gandetect.utils import set_seed\n",
        "\n",
        "EVAL_DATASETS = {\n",
        "    \"ProGAN\": \"progan\",\n",
        "    \"StyleGAN\": \"stylegan\",\n",
        "    \"StyleGAN2\": \"stylegan2\",\n",
        "    \"BigGAN\": \"biggan\",\n",
        "    \"CycleGAN\": \"cyclegan\",\n",
        "    \"StarGAN\": \"stargan\",\n",
        "    \"GauGAN\": \"gaugan\",\n",
        "    \"CRN\": \"crn\",\n",
        "    \"IMLE\": \"imle\",\n",
        "    \"SITD\": \"seeingdark\",\n",
        "    \"SAN\": \"san\",\n",
        "    \"DeepFake\": \"deepfake\",\n",
        "    \"Whichfaceisreal\": \"whichface\",\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBo4uxNA7pZ5",
        "outputId": "7b9f6885-2b68-41a9-e5c6-7c0d87443f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CNNDetection'...\n",
            "remote: Enumerating objects: 632, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 632 (delta 25), reused 25 (delta 25), pack-reused 604\u001b[K\n",
            "Receiving objects: 100% (632/632), 6.36 MiB | 18.83 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PeterWang512/CNNDetection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9q7Ko2W7r8x",
        "outputId": "f7e7b8e0-7c63-42ca-904a-1ba06f6c5a57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CNNDetection\n"
          ]
        }
      ],
      "source": [
        "%cd /content/CNNDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-6Rwmj5_PZm"
      },
      "source": [
        "# Download the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DQ-F-LE8waQ",
        "outputId": "60ed0d1a-d7e4-477e-c28b-b4e1ad7d4ecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RecfzmtP_Dr5"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/EECS6322/CNN_synth_testset.zip ./test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s03_4ZsM_3jJ",
        "outputId": "f52882ab-d03e-4acd-9d32-e5e4c4e05c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./test’: File exists\n",
            "Archive:  ./test\n",
            "checkdir:  cannot create extraction directory: ./test\n",
            "           File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ./test_dir/\n",
        "!unzip ./test.zip -d ./test_dir\n",
        "!rm ./test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgvyKAr06szi"
      },
      "outputs": [],
      "source": [
        "# models to evaluate\n",
        "models_dir = \"~/content/models/models\"\n",
        "\n",
        "# data to use for evaluation\n",
        "eval_dir = \"~/content/CNNDetection/dataset/test\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKsUlzJpM4mu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from gandetect.dataloader import load_data\n",
        "from gandetect.transforms import TEST_TRANSFORM, TEST_TRANSFORM_DCT\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "from PIL import Image\n",
        "from sklearn.metrics import average_precision_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "EVAL_DATASETS = {\n",
        "    \"ProGAN\": \"progan\"\n",
        "}\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def evaluate_model(model_path, dataset_path):\n",
        "    # prepare the dataset for testing\n",
        "    transform = TEST_TRANSFORM\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "                  torch.utils.data.ConcatDataset(\n",
        "                    load_data(dataset_path, transformations=transform)),\n",
        "                  num_workers=mp.cpu_count(), batch_size=batch_size)\n",
        "\n",
        "\n",
        "    model = torch.load(model_path)\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    mAP = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        print(f\"Evaluating model...{model_path}\")\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for batch in tqdm(dataloader):\n",
        "            ims, labels = batch\n",
        "            ims = ims.to(device)\n",
        "            preds = model(ims).sigmoid().float().flatten().tolist()\n",
        "\n",
        "            y_true.extend(labels.float().flatten().tolist())\n",
        "            y_pred.extend(preds)\n",
        "            \n",
        "        print(average_precision_score(y_true, y_pred))\n",
        "        mAP.append(average_precision_score(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R9IXRq0M5sV"
      },
      "outputs": [],
      "source": [
        "model_path = \"/content/models/models/16_datasets/blur_jpeg_5/resnet50/checkpoint.pth\"\n",
        "dataset_path = \"/content/test_dir\"\n",
        "\n",
        "evaluate_model(model_path, dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBJaJEGzqTQ2"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import multiprocessing as mp\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.metrics import average_precision_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "from gandetect.dataloader import load_data\n",
        "from gandetect.transforms import TEST_TRANSFORM, TEST_TRANSFORM_DCT\n",
        "from gandetect.utils import set_seed\n",
        "\n",
        "EVAL_DATASETS = {\n",
        "    \"ProGAN\": \"progan\",\n",
        "    \"StyleGAN\": \"stylegan\",\n",
        "    \"StyleGAN2\": \"stylegan2\",\n",
        "    \"BigGAN\": \"biggan\",\n",
        "    \"CycleGAN\": \"cyclegan\",\n",
        "    \"StarGAN\": \"stargan\",\n",
        "    \"GauGAN\": \"gaugan\",\n",
        "    \"CRN\": \"crn\",\n",
        "    \"IMLE\": \"imle\",\n",
        "    \"SITD\": \"seeingdark\",\n",
        "    \"SAN\": \"san\",\n",
        "    \"DeepFake\": \"deepfake\",\n",
        "    \"Whichfaceisreal\": \"whichface\",\n",
        "}\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    set_seed(42)\n",
        "    models_paths = [str(path.absolute())\n",
        "                    for path in Path(args.MODELS).rglob(\"checkpoint.pth\")]\n",
        "\n",
        "    # prep datasets\n",
        "    datasets = {name: f\"{args.DIR}/{path}\"\n",
        "                for name, path in EVAL_DATASETS.items()}\n",
        "\n",
        "    if not args.include_new:\n",
        "        del datasets[\"StyleGAN2\"]\n",
        "        del datasets[\"Whichfaceisreal\"]\n",
        "\n",
        "    transfrom = TEST_TRANSFORM_DCT if args.dct else TEST_TRANSFORM\n",
        "    datasets = {name: torch.utils.data.DataLoader(\n",
        "        torch.utils.data.ConcatDataset(\n",
        "            load_data(dataset_path, transformations=transfrom)),\n",
        "        num_workers=mp.cpu_count(), batch_size=args.batch_size) for name, dataset_path in datasets.items()}\n",
        "\n",
        "    with open(f\"{args.result_file_name}.csv\", \"w+\") as csv, open(f\"{args.result_file_name}.tex\", \"w+\") as tex:\n",
        "        # headers\n",
        "        csv.write(f\"Name,{','.join(datasets.keys())},mAP\\n\")\n",
        "\n",
        "        tex.write(r\"\\begin{tabular}{\" + f\"{'cc' + len(datasets)* 'c'}\"+\"}\\n\")\n",
        "        tex.write(\"\\\\toprule\\n\")\n",
        "        tex.write(r\"Name &\")\n",
        "        for name in datasets.keys():\n",
        "            tex.write(f\"{name} &\")\n",
        "        tex.write(r\"mAP \\\\\" + \"\\n\")\n",
        "\n",
        "        for model_path in models_paths:\n",
        "            print(f\"Evaluating {model_path}\")\n",
        "            model = torch.load(model_path)\n",
        "            model = model.eval()\n",
        "\n",
        "            csv.write(f\"{model_path},\")\n",
        "\n",
        "            # name needs to be changed before table compiles\n",
        "            tex.write(f\"{model_path} &\")\n",
        "\n",
        "            device = torch.device(\n",
        "                \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "            mAP = []\n",
        "            print(f\"============================\")\n",
        "            with torch.no_grad():\n",
        "                for name, dataloader in datasets.items():\n",
        "                    print(f\"Evaluating {name}!\")\n",
        "                    y_true, y_pred = [], []\n",
        "                    for batch in tqdm(dataloader):\n",
        "                        imgs, labels = batch\n",
        "                        imgs = imgs.to(device)\n",
        "                        predictions = model(\n",
        "                            imgs).sigmoid().float().flatten().tolist()\n",
        "\n",
        "                        y_true.extend(labels.float().flatten().tolist())\n",
        "                        y_pred.extend(predictions)\n",
        "\n",
        "                    ap = average_precision_score(y_true=y_true, y_score=y_pred)\n",
        "                    print(f\"{name} - {ap:.2%}\")\n",
        "                    csv.write(f\"{ap * 100:.1f},\")\n",
        "                    tex.write(f\"{ap * 100:.1f} &\")\n",
        "                    mAP.append(ap)\n",
        "                    print(f\"============================\")\n",
        "\n",
        "            mAP = np.mean(mAP)\n",
        "            print(f\"mAP: {mAP:.2%}\")\n",
        "            csv.write(f\"{mAP * 100:.1f}\\n\")\n",
        "            tex.write(f\"{mAP * 100:.1f}\" + r\"\\\\ \\midrule\" + \"\\n\")\n",
        "\n",
        "        tex.write(r\"\\end{tabular}\")\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"MODELS\", help=\"Model to use.\", type=str)\n",
        "    parser.add_argument(\"DIR\", help=\"Directory to analyse.\", type=str)\n",
        "\n",
        "    default_batch = 64\n",
        "    parser.add_argument(\n",
        "        \"--batch_size\", help=f\"Batch size to use default: {default_batch}.\", default=default_batch)\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--include_new\", help=\"Includes StyleGAN2 and Whichfaceisreal in the evaluation.\", action=\"store_true\")\n",
        "    parser.add_argument(\n",
        "        \"--dct\", help=\"Use DCT preprocessing instead.\", action=\"store_true\")\n",
        "\n",
        "    results_file = \"results\"\n",
        "    parser.add_argument(\n",
        "        \"--result_file_name\", \"-r\", help=\"Result file name for csv/tex; default: {results_file}.\", type=str, default=results_file)\n",
        "\n",
        "    return parser.parse_args()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4KVzMhuxDG4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# models to evaluate\n",
        "models_dir = \"~/content/models/models\"\n",
        "\n",
        "# data to use for evaluation\n",
        "eval_dir = \"~/content/CNNDetection/dataset/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzQlwacixuES",
        "outputId": "871dfe1b-1105-4e1c-e4de-fac8771f59e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ReproducabilityCNNEasyToSpot\n"
          ]
        }
      ],
      "source": [
        "%cd ./ReproducabilityCNNEasyToSpot/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP93omhQx0G8",
        "outputId": "f7301f56-9745-43e9-a9af-7ce3873081ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNNDetection  gandetect  models.zip\t\t       results.csv  sample_data\n",
            "drive\t      models\t ReproducabilityCNNEasyToSpot  results.tex\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7anU6EBWyLHH"
      },
      "outputs": [],
      "source": [
        "import gandetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW0efzYOysId",
        "outputId": "68f7f484-638d-4851-9190-8fc6a1dab55b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krj4kS4KA3fF",
        "outputId": "2b9c64cf-ebf0-4b6e-8a4e-50fced3dfbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ReproducabilityCNNEasyToSpot\n"
          ]
        }
      ],
      "source": [
        "%cd ./ReproducabilityCNNEasyToSpot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ5akMK2xCm7"
      },
      "outputs": [],
      "source": [
        "!python evaluate.py ~/content/models/models/20_datasets/blur_jpeg_1/  ~/content/test_dir/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pUS0GsEDtez"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
